{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgdn91YIpnE/S+rNiJLT1a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayandas96476/RAG/blob/main/Sparse_retrieval_wikipedia_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8ihY81ft7jgp"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain-groq langchain\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"  # Replace with your actual API key\n"
      ],
      "metadata": {
        "id": "ER33b2lYPcR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b50447-b23c-4fba-986c-eedec3d015a0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_full_wikipedia_content(title):\n",
        "    # Construct the URL for the full Wikipedia page\n",
        "    url = f\"https://en.wikipedia.org/wiki/{title.replace(' ', '_')}\"\n",
        "\n",
        "    try:\n",
        "        # Make the request\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse the HTML content\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find the main content div\n",
        "        content_div = soup.find(id=\"mw-content-text\")\n",
        "\n",
        "        # Extract all paragraphs\n",
        "        paragraphs = content_div.find_all('p')\n",
        "\n",
        "        # Combine all paragraph texts\n",
        "        full_text = '\\n\\n'.join([para.get_text() for para in paragraphs])\n",
        "\n",
        "        # Remove citations [1], [2], etc.\n",
        "        import re\n",
        "        full_text = re.sub(r'\\[\\d+\\]', '', full_text)\n",
        "\n",
        "        return full_text.strip()\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        return f\"Error fetching page: {str(e)}\"\n",
        "\n",
        "# First install beautifulsoup4 if you haven't:\n",
        "# pip install beautifulsoup4\n",
        "\n",
        "# Example usage\n"
      ],
      "metadata": {
        "id": "bHJKEimH8VA6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def combine_strings(original_list, chunk_size=3):\n",
        "    return [''.join(original_list[i:i + chunk_size])\n",
        "            for i in range(0, len(original_list), chunk_size)]\n",
        "\n"
      ],
      "metadata": {
        "id": "bcIXFKNM8Vzg"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenize\n",
        "    words = text.split()\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "\n",
        "    # Lemmatize\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n"
      ],
      "metadata": {
        "id": "UFmMqm7z8iHs"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = \"Batman\"\n",
        "text = get_full_wikipedia_content(title)\n",
        "text = text.replace('\\n', '')\n",
        "\n",
        "lis = text.split(\".\")\n",
        "\n",
        "combined = combine_strings(lis)\n",
        "text = \"\"\" \"\"\"\n",
        "for i in combined:\n",
        "  text += i+\"\\n\\n\\n\"\n",
        "\n",
        "documents = text.split(\"\\n\\n\\n\")\n",
        "len(documents)\n",
        "\n",
        "preprocessed_docs = [preprocess_text(doc) for doc in documents]"
      ],
      "metadata": {
        "id": "21LkfWuzNp11"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a ChatGroq instance\n",
        "llm = ChatGroq(\n",
        "    model_name=\"mixtral-8x7b-32768\",  # You can also use \"llama2-70b-4096\"\n",
        "    temperature=0.7,\n",
        "    max_tokens=1024\n",
        ")"
      ],
      "metadata": {
        "id": "wHm3J_mdC7_P"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_context(preprocessed_docs,query):\n",
        "\n",
        "  # Step 2: Initialize the TfidfVectorizer\n",
        "  vectorizer = TfidfVectorizer()\n",
        "\n",
        "  # Step 3: Fit and transform the documents to generate the TF-IDF matrix\n",
        "  tfidf_matrix = vectorizer.fit_transform(preprocessed_docs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Step 5: Transform the query into a TF-IDF vector\n",
        "  query_vector = vectorizer.transform([query])\n",
        "\n",
        "  # Step 6: Compute cosine similarity between the query and the documents\n",
        "  cosine_similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "\n",
        "  # Step 7: Get the top 3 results based on similarity scores\n",
        "  top_n = 10\n",
        "  top_indices = np.argsort(cosine_similarities)[::-1][:top_n]\n",
        "\n",
        "  CONTEXT = \"\"\"\"\"\"\n",
        "\n",
        "  for i, idx in enumerate(top_indices):\n",
        "      CONTEXT+= documents[idx] + \"\\n\"+ \"================\"+\"\\n\"\n",
        "  return CONTEXT"
      ],
      "metadata": {
        "id": "h9QtnODND4SP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(CONTEXT,query):\n",
        "  template=prompt = f\"\"\"\n",
        "  use the following CONTEXT to answer the QUESTION at the end.\n",
        "  If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\n",
        "  Also remember dont use any external knowledge and only refer to this CONTEXT to answer question.\n",
        "  Consider this CONTEXT as the ultimate truth.\n",
        "\n",
        "  CONTEXT: {CONTEXT}\n",
        "  QUESTION: {query}\n",
        "\n",
        "  \"\"\"\n",
        "  prompt = PromptTemplate(\n",
        "      input_variables=[\"query\",\"CONTEXT\"],\n",
        "      template=template\n",
        "  )\n",
        "\n",
        "  chain = LLMChain(llm=llm, prompt=prompt)\n",
        "  response = chain.invoke({\"query\": query, \"CONTEXT\":CONTEXT})\n",
        "  return response['text']"
      ],
      "metadata": {
        "id": "EVNDoOs5MTwS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who created Batman comic\"\n",
        "CONTEXT = get_context(preprocessed_docs,query)\n",
        "answer = retrieve(CONTEXT,query)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "pGddxwjOMmn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2dad1b6-5b90-448c-b744-41b859725436"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batman was created by the artist Bob Kane and writer Bill Finger.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who was batmans girlfriend\"\n",
        "CONTEXT = get_context(preprocessed_docs,query)\n",
        "answer = retrieve(CONTEXT,query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJp6igGhND3S",
        "outputId": "47ced64c-7a70-4e7d-90f4-4eaaa23b5782"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The context does not provide information about Batman's girlfriend. Batman's romantic relationships are not mentioned or discussed in the given text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Any idea on Batman's love life\"\n",
        "CONTEXT = get_context(preprocessed_docs,query)\n",
        "answer = retrieve(CONTEXT,query)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "mO0KWgaVNIbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d97652-736b-4711-de80-3e0974b5cbfa"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided context, Batman's love life is quite complex and spans many decades. His first love interest was Julie Madison, and over the years, he has had many significant relationships. Vicki Vale, a journalist, is another important figure in his love life. However, her attempts to uncover Batman's true identity led to a complicated romantic involvement that waxed and waned over the years.\n",
            "\n",
            "Selina Kyle, also known as Catwoman, is perhaps the most notable figure in Batman's romantic history. Their relationship is characterized by a blend of romance and rivalry. Despite the challenges, their love story resulted in the birth of Damian Wayne, who would grow to become the latest Robin and add a new layer of complexity to Batman's character.\n",
            "\n",
            "Batman was also engaged to Talia al Ghul, but he had to break off the engagement due to her father's criminal ambitions and the conflict it caused in their relationship. His relationship with Wonder Woman has also been explored in various storylines, but it remains largely unexplored, often overshadowed by their respective commitments.\n",
            "\n",
            "In addition, Batman's relationship with Alfred Pennyworth, his butler and trusted ally, is not romantic but is a crucial part of his life, offering both emotional support and practical assistance in Batman's crime-fighting endeavors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who was Batman's most ferocious enemy?\"\n",
        "CONTEXT = get_context(preprocessed_docs,query)\n",
        "answer = retrieve(CONTEXT,query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHFzUqdjQC3i",
        "outputId": "6676761c-58c7-413e-d22c-5a46f6e91c34"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided context, it is not explicitly stated who Batman's most ferocious enemy is. However, Ghost-Maker, Scarecrow, Bane, and the Magistrate led by Simon Saint are all mentioned as enemies of Batman. Between these, Bane is depicted as a particularly formidable and physically powerful foe. In the provided context, it is also mentioned that Bane travels to Gotham after healing from his wounds to fight Batman, indicating a persistent and tenacious enmity. Therefore, based on the given information, it could be argued that Bane is one of Batman's more ferocious enemies. However, it is important to note that the context does not provide enough information to definitively answer this question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ozT-3U-rQJi9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}