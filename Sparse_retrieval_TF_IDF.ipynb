{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPURm2YB35TVtbaw+TMKWl2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayandas96476/RAG/blob/main/Sparse_retrieval_TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF method was used to retrieve related docs based on a query"
      ],
      "metadata": {
        "id": "YYD-3Civ34eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "6DOM2mDn4EEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 1: Define the documents (your corpus)\n",
        "documents = [\n",
        "    \"I love programming in Python.\",\n",
        "    \"Python is a versatile programming language.\",\n",
        "    \"Machine learning and AI are exciting fields.\",\n",
        "    \"I enjoy solving problems using Python.\",\n",
        "    \"Cooking and baking are creative activities.\"\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "wqP8cm4lH1LF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Tokenize\n",
        "    words = text.split()\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "\n",
        "    # Lemmatize\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "preprocessed_docs = [preprocess_text(doc) for doc in documents]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1BkvO9p2rSe",
        "outputId": "8c249d3e-cc8b-432e-c028-add071eafd7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(preprocessed_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuQKmmZs3L6f",
        "outputId": "23bfb3db-77a8-46b6-b193-8de8612b0b05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Initialize the TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Step 3: Fit and transform the documents to generate the TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform(preprocessed_docs)\n",
        "\n"
      ],
      "metadata": {
        "id": "dSkGzMmsH-yp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define the search query\n",
        "query = \"Python programming\"\n",
        "\n",
        "# Step 5: Transform the query into a TF-IDF vector\n",
        "query_vector = vectorizer.transform([query])\n"
      ],
      "metadata": {
        "id": "pMfWQKaTICMm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(tfidf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "qvRpt5AWIHIi",
        "outputId": "ceef863d-2975-4840-95fe-a913db3645e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse._csr.csr_matrix"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>scipy.sparse._csr.csr_matrix</b><br/>def __init__(arg1, shape=None, dtype=None, copy=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/scipy/sparse/_csr.py</a>Compressed Sparse Row matrix.\n",
              "\n",
              "This can be instantiated in several ways:\n",
              "    csr_matrix(D)\n",
              "        where D is a 2-D ndarray\n",
              "\n",
              "    csr_matrix(S)\n",
              "        with another sparse array or matrix S (equivalent to S.tocsr())\n",
              "\n",
              "    csr_matrix((M, N), [dtype])\n",
              "        to construct an empty matrix with shape (M, N)\n",
              "        dtype is optional, defaulting to dtype=&#x27;d&#x27;.\n",
              "\n",
              "    csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
              "        where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
              "        relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
              "\n",
              "    csr_matrix((data, indices, indptr), [shape=(M, N)])\n",
              "        is the standard CSR representation where the column indices for\n",
              "        row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their\n",
              "        corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.\n",
              "        If the shape parameter is not supplied, the matrix dimensions\n",
              "        are inferred from the index arrays.\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "dtype : dtype\n",
              "    Data type of the matrix\n",
              "shape : 2-tuple\n",
              "    Shape of the matrix\n",
              "ndim : int\n",
              "    Number of dimensions (this is always 2)\n",
              "nnz\n",
              "size\n",
              "data\n",
              "    CSR format data array of the matrix\n",
              "indices\n",
              "    CSR format index array of the matrix\n",
              "indptr\n",
              "    CSR format index pointer array of the matrix\n",
              "has_sorted_indices\n",
              "has_canonical_format\n",
              "T\n",
              "\n",
              "Notes\n",
              "-----\n",
              "\n",
              "Sparse matrices can be used in arithmetic operations: they support\n",
              "addition, subtraction, multiplication, division, and matrix power.\n",
              "\n",
              "Advantages of the CSR format\n",
              "  - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
              "  - efficient row slicing\n",
              "  - fast matrix vector products\n",
              "\n",
              "Disadvantages of the CSR format\n",
              "  - slow column slicing operations (consider CSC)\n",
              "  - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
              "\n",
              "Canonical Format\n",
              "    - Within each row, indices are sorted by column.\n",
              "    - There are no duplicate entries.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "\n",
              "&gt;&gt;&gt; import numpy as np\n",
              "&gt;&gt;&gt; from scipy.sparse import csr_matrix\n",
              "&gt;&gt;&gt; csr_matrix((3, 4), dtype=np.int8).toarray()\n",
              "array([[0, 0, 0, 0],\n",
              "       [0, 0, 0, 0],\n",
              "       [0, 0, 0, 0]], dtype=int8)\n",
              "\n",
              "&gt;&gt;&gt; row = np.array([0, 0, 1, 2, 2, 2])\n",
              "&gt;&gt;&gt; col = np.array([0, 2, 2, 0, 1, 2])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
              "&gt;&gt;&gt; csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
              "array([[1, 0, 2],\n",
              "       [0, 0, 3],\n",
              "       [4, 5, 6]])\n",
              "\n",
              "&gt;&gt;&gt; indptr = np.array([0, 2, 3, 6])\n",
              "&gt;&gt;&gt; indices = np.array([0, 2, 2, 0, 1, 2])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 3, 4, 5, 6])\n",
              "&gt;&gt;&gt; csr_matrix((data, indices, indptr), shape=(3, 3)).toarray()\n",
              "array([[1, 0, 2],\n",
              "       [0, 0, 3],\n",
              "       [4, 5, 6]])\n",
              "\n",
              "Duplicate entries are summed together:\n",
              "\n",
              "&gt;&gt;&gt; row = np.array([0, 1, 2, 0])\n",
              "&gt;&gt;&gt; col = np.array([0, 1, 1, 0])\n",
              "&gt;&gt;&gt; data = np.array([1, 2, 4, 8])\n",
              "&gt;&gt;&gt; csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
              "array([[9, 0, 0],\n",
              "       [0, 2, 0],\n",
              "       [0, 4, 0]])\n",
              "\n",
              "As an example of how to construct a CSR matrix incrementally,\n",
              "the following snippet builds a term-document matrix from texts:\n",
              "\n",
              "&gt;&gt;&gt; docs = [[&quot;hello&quot;, &quot;world&quot;, &quot;hello&quot;], [&quot;goodbye&quot;, &quot;cruel&quot;, &quot;world&quot;]]\n",
              "&gt;&gt;&gt; indptr = [0]\n",
              "&gt;&gt;&gt; indices = []\n",
              "&gt;&gt;&gt; data = []\n",
              "&gt;&gt;&gt; vocabulary = {}\n",
              "&gt;&gt;&gt; for d in docs:\n",
              "...     for term in d:\n",
              "...         index = vocabulary.setdefault(term, len(vocabulary))\n",
              "...         indices.append(index)\n",
              "...         data.append(1)\n",
              "...     indptr.append(len(indices))\n",
              "...\n",
              "&gt;&gt;&gt; csr_matrix((data, indices, indptr), dtype=int).toarray()\n",
              "array([[2, 1, 0, 0],\n",
              "       [0, 1, 1, 1]])</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 370);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get number of documents (rows)\n",
        "n_docs = tfidf_matrix.shape[0]\n",
        "print(\"Number of vectors\", n_docs)\n",
        "\n",
        "# Get number of terms/features (columns)\n",
        "n_terms = tfidf_matrix.shape[1]\n",
        "print(\"features of a vector\", n_terms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlA_PJllIJdI",
        "outputId": "a0eca6c6-dabc-4a9c-9f1d-14fa2481f9ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of vectors 5\n",
            "features of a vector 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 6: Compute cosine similarity between the query and the documents\n",
        "cosine_similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "\n",
        "# Step 7: Get the top 3 results based on similarity scores\n",
        "top_n = 3\n",
        "top_indices = np.argsort(cosine_similarities)[::-1][:top_n]\n",
        "\n",
        "# Step 8: Print the results\n",
        "print(\"Top 3 Search Results:\")\n",
        "for i, idx in enumerate(top_indices):\n",
        "    print(f\"{i + 1}. Document: {documents[idx]} (Score: {cosine_similarities[idx]:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8DRywHLIMs-",
        "outputId": "1e10fdbe-577c-4a59-d103-2ddcbfc121b5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Search Results:\n",
            "1. Document: I love programming in Python. (Score: 0.7237)\n",
            "2. Document: Python is a versatile programming language. (Score: 0.5956)\n",
            "3. Document: I enjoy solving problems using Python. (Score: 0.2028)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MXCP2CtOJRzV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}